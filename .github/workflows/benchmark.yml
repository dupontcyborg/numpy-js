name: Benchmark Tracking

on:
  # push:
  #   branches: [main]
  workflow_dispatch:

# Don't run multiple benchmark jobs at once
concurrency:
  group: benchmark-main
  cancel-in-progress: false

jobs:
  benchmark:
    name: Run and Track Benchmarks
    runs-on: ubuntu-latest
    environment: benchmark
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history for regression detection
          token: ${{ secrets.PAT_TOKEN }}
          persist-credentials: true

      - uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: 'npm'

      - uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: |
          pip install numpy
          npm ci

      - name: Run benchmarks
        run: npm run bench:quick

      - name: Prepare benchmark history directory
        run: |
          mkdir -p .github/benchmark-history

      - name: Save benchmark results with metadata
        id: save_results
        run: |
          # Get commit info
          COMMIT_SHA="${{ github.sha }}"
          COMMIT_SHORT="${COMMIT_SHA:0:7}"
          COMMIT_DATE=$(git log -1 --format=%cI)

          # Create filename with timestamp and commit
          TIMESTAMP=$(date -u +"%Y%m%d-%H%M%S")
          FILENAME="benchmark-${TIMESTAMP}-${COMMIT_SHORT}.json"

          # Add metadata to benchmark results (using Node.js to safely handle commit message)
          node << 'SCRIPT'
          const fs = require('fs');
          const { execSync } = require('child_process');

          const results = JSON.parse(fs.readFileSync('benchmarks/results/latest.json', 'utf8'));
          const commitMsg = execSync('git log -1 --pretty=%B', { encoding: 'utf8' }).split('\n')[0];

          results.metadata = {
            commit: process.env.COMMIT_SHA,
            commitShort: process.env.COMMIT_SHORT,
            commitMessage: commitMsg,
            commitDate: process.env.COMMIT_DATE,
            timestamp: process.env.TIMESTAMP,
            nodeVersion: process.version,
            platform: process.platform,
            arch: process.arch
          };

          fs.writeFileSync(`.github/benchmark-history/${process.env.FILENAME}`, JSON.stringify(results, null, 2));
          console.log(`Saved benchmark results to .github/benchmark-history/${process.env.FILENAME}`);
          SCRIPT

          echo "filename=${FILENAME}" >> $GITHUB_OUTPUT
          echo "commit_short=${COMMIT_SHORT}" >> $GITHUB_OUTPUT

      - name: Detect regressions
        id: detect_regression
        run: |
          node -e "
          const fs = require('fs');
          const path = require('path');

          // Get all historical benchmark files
          const historyDir = '.github/benchmark-history';

          // Check if directory exists and has files
          if (!fs.existsSync(historyDir)) {
            console.log('No benchmark history yet');
            process.exit(0);
          }

          const files = fs.readdirSync(historyDir)
            .filter(f => f.endsWith('.json'))
            .sort()
            .reverse();

          if (files.length < 2) {
            console.log('Not enough history to compare (need at least 2 runs)');
            process.exit(0);
          }

          // Current benchmark (just saved)
          const currentFile = files[0];
          const current = JSON.parse(fs.readFileSync(path.join(historyDir, currentFile), 'utf8'));

          // Previous benchmark
          const previousFile = files[1];
          const previous = JSON.parse(fs.readFileSync(path.join(historyDir, previousFile), 'utf8'));

          const currentOps = current.benchmarks || [];
          const previousOps = previous.benchmarks || [];

          let hasRegression = false;
          let regressionDetails = [];
          const threshold = 1.5; // 50% regression threshold for main branch

          console.log('Comparing benchmarks:');
          console.log('  Current:', currentFile);
          console.log('  Previous:', previousFile);
          console.log('');

          currentOps.forEach(currentOp => {
            const prevOp = previousOps.find(p => p.name === currentOp.name);
            if (prevOp && prevOp.time && currentOp.time) {
              const ratio = currentOp.time / prevOp.time;
              const change = ((ratio - 1) * 100).toFixed(1);

              console.log(\`  \${currentOp.name}: \${change > 0 ? '+' : ''}\${change}%\`);

              if (ratio > threshold) {
                hasRegression = true;
                regressionDetails.push({
                  name: currentOp.name,
                  previousTime: prevOp.time,
                  currentTime: currentOp.time,
                  ratio: ratio,
                  change: change
                });
              }
            }
          });

          if (hasRegression) {
            console.log('');
            console.log('⚠️  REGRESSION DETECTED:');
            regressionDetails.forEach(r => {
              console.log(\`  - \${r.name}: \${r.previousTime.toFixed(2)}ms → \${r.currentTime.toFixed(2)}ms (+\${r.change}%)\`);
            });

            fs.writeFileSync('regression-report.json', JSON.stringify(regressionDetails, null, 2));
          }

          console.log('HAS_REGRESSION=' + hasRegression);
          " > regression-check.txt

          cat regression-check.txt

          has_regression=$(grep "HAS_REGRESSION=true" regression-check.txt || echo "false")
          if [ "$has_regression" = "HAS_REGRESSION=true" ]; then
            echo "has_regression=true" >> $GITHUB_OUTPUT
          else
            echo "has_regression=false" >> $GITHUB_OUTPUT
          fi

      - name: Generate benchmark visualization
        run: |
          node -e "
          const fs = require('fs');
          const path = require('path');

          // Load all benchmark history
          const historyDir = '.github/benchmark-history';

          // Check if directory exists
          if (!fs.existsSync(historyDir)) {
            console.log('No benchmark history directory found');
            process.exit(0);
          }

          const files = fs.readdirSync(historyDir)
            .filter(f => f.endsWith('.json'))
            .sort();

          const history = files.map(file => {
            const data = JSON.parse(fs.readFileSync(path.join(historyDir, file), 'utf8'));
            return {
              file: file,
              metadata: data.metadata,
              benchmarks: data.benchmarks
            };
          });

          // Generate markdown report
          let report = '# Benchmark History\n\n';
          report += \`Last updated: \${new Date().toISOString()}\n\n\`;
          report += \`Total benchmark runs: \${history.length}\n\n\`;

          if (history.length > 0) {
            const latest = history[history.length - 1];
            report += '## Latest Results\n\n';
            report += \`- Commit: \${latest.metadata?.commitShort || 'unknown'}\n\`;
            report += \`- Date: \${latest.metadata?.commitDate || 'unknown'}\n\`;
            report += \`- Message: \${latest.metadata?.commitMessage || 'unknown'}\n\n\`;

            report += '| Operation | Time (ms) | vs Previous |\n';
            report += '|-----------|-----------|-------------|\n';

            const previous = history.length > 1 ? history[history.length - 2] : null;

            (latest.benchmarks || []).forEach(bench => {
              let change = '-';
              if (previous) {
                const prevBench = (previous.benchmarks || []).find(b => b.name === bench.name);
                if (prevBench && prevBench.time) {
                  const ratio = bench.time / prevBench.time;
                  const changePct = ((ratio - 1) * 100).toFixed(1);
                  change = changePct > 0 ? \`+\${changePct}%\` : \`\${changePct}%\`;
                }
              }
              report += \`| \${bench.name} | \${bench.time?.toFixed(2) || 'N/A'} | \${change} |\n\`;
            });

            // Show trend over last 10 runs
            if (history.length > 1) {
              report += '\n## Recent Trend (Last 10 Runs)\n\n';
              const recentHistory = history.slice(-10);

              // Get unique operation names
              const opNames = [...new Set(recentHistory.flatMap(h =>
                (h.benchmarks || []).map(b => b.name)
              ))];

              opNames.forEach(opName => {
                report += \`\n### \${opName}\n\n\`;
                report += '| Commit | Date | Time (ms) |\n';
                report += '|--------|------|----------|\n';

                recentHistory.forEach(h => {
                  const bench = (h.benchmarks || []).find(b => b.name === opName);
                  if (bench) {
                    const commit = h.metadata?.commitShort || 'unknown';
                    const date = h.metadata?.commitDate ? new Date(h.metadata.commitDate).toLocaleDateString() : 'unknown';
                    const time = bench.time?.toFixed(2) || 'N/A';
                    report += \`| \${commit} | \${date} | \${time} |\n\`;
                  }
                });
              });
            }
          }

          fs.writeFileSync('.github/benchmark-history/BENCHMARK-HISTORY.md', report);
          console.log('Generated benchmark history report');
          "

      - name: Commit benchmark results
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add .github/benchmark-history/

          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "chore: update benchmark results [${{ steps.save_results.outputs.commit_short }}]" -m "[skip ci]"
            git push
          fi

      - name: Create issue on regression
        if: steps.detect_regression.outputs.has_regression == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const regressions = JSON.parse(fs.readFileSync('regression-report.json', 'utf8'));

            let body = '## ⚠️ Performance Regression Detected\n\n';
            body += `Commit: ${{ github.sha }}\n\n`;
            body += '### Affected Operations\n\n';
            body += '| Operation | Previous | Current | Change |\n';
            body += '|-----------|----------|---------|--------|\n';

            regressions.forEach(r => {
              body += `| ${r.name} | ${r.previousTime.toFixed(2)}ms | ${r.currentTime.toFixed(2)}ms | +${r.change}% |\n`;
            });

            body += '\n### Action Required\n\n';
            body += 'Please investigate the performance regression and consider:\n';
            body += '1. Reverting the change if unintentional\n';
            body += '2. Optimizing the implementation\n';
            body += '3. Documenting if the regression is acceptable\n\n';
            body += `[View benchmark history](${context.payload.repository.html_url}/blob/main/.github/benchmark-history/BENCHMARK-HISTORY.md)`;

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Performance Regression in ${{ steps.save_results.outputs.commit_short }}`,
              body: body,
              labels: ['performance', 'regression']
            });

      - name: Upload benchmark artifacts
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ steps.save_results.outputs.commit_short }}
          path: |
            benchmarks/results/latest.json
            benchmarks/results/plots/
          retention-days: 90
